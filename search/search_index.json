{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Robot Guides","text":"<p>This repository contains the documentation for the robots we have in the lab.</p> <p>Are you lost?</p> <p>This website outlines the operating proceedures for the robots we have in the lab at the University of Southampton. (This documentation may be useful to others.) For the main lab website, please click here.</p> <p>These guides were written by Toby Godfrey (t.godfrey ~at~ soton.ac.uk). If there are errors or omissions, please inform me as soon as possible.</p> <p>If you have encountered an issue with a robot, please inform us immediately by completing this form https://forms.office.com/e/gP7mZcBhfr. Please complete the form even if the robot has recovered.</p> <p>Non-Linux Systems</p> <p>This guide was written for Linux systems. If you are using a different OS, some of this information may not work for you (mainly the code segments). If you overcome such issues, please submit a PR on GitHub to make these guides more comprehensive.</p>"},{"location":"#general-information","title":"General Information","text":"<ul> <li>Do not store your working files on the robots; robot storage will be wiped on a regular basis.</li> <li>Major changes to robot software or configuration should not be conducted unless it has been discussed and approved by an experienced user. If you need to discuss such a change please email Toby Godfrey (t.godfrey ~at~ soton.ac.uk).</li> <li>If you wish to contribute a guide for a specific robot type please submit a PR on the GitHub.</li> <li>This is not a guide on ROS! The purpose of these documents is to allow users to easily utilise the robotic platforms that we have in the lab. (For help with ROS and other robotics ideas take a look here.)</li> </ul>"},{"location":"report_an_issue/","title":"Reporting an Issue","text":"<p>It is important that we know of any issues or damage that occur with the robots. Even if the robot has recovered from the issue, please still complete the form below. This helps us keep track of problems and diagnose issue before they become major.</p> <p>https://forms.office.com/e/gP7mZcBhfr</p> <p>If the form misses some information you deem important, please email Toby Godfrey (t.godfrey ~at~ soton.ac.uk) and Dr Mohammad D. Soorati (m.soorati ~at~ soton.ac.uk).</p>"},{"location":"go2/","title":"Go2","text":"<p>This directory contains the documentation for the Go2 platform.</p> <p>We currently have three Go2 platforms in the lab. At the time of writing only one has been set up.</p> <p>If you have not used the Go2s before, please see Getting Started.</p> <p>For all other information about the Go2s, please navigate to the relevant page.</p> <ul> <li>Getting Started</li> <li>ROS2 Control</li> <li>Troubleshooting</li> <li>Useful Resources</li> </ul>"},{"location":"go2/3d_models/","title":"3D Models","text":"<p>This page lists the 3D models we have created or use with the Go2 robots.</p>"},{"location":"go2/3d_models/#realsense-camera-mount","title":"RealSense Camera Mount","text":"<p>This mount holds an Intel RealSense RGBD camera on the front of the robot. This was created by Natapat Kirdwichai (nk3g22 ~at~ soton.ac.uk).</p> <ul> <li>Base</li> <li>Camera Mount</li> </ul> <p>The images below show the mount in use on the robot.</p>"},{"location":"go2/external_lidar/","title":"External LiDAR","text":"<p>We have a Livox MID-360 LiDAR which mounts on the back of the Go2 to provide a more comprehensive scan of the environment when compared to the built-in LiDAR.</p> <p>This has not yet been set up as we need to source/create a mounting plate and a cable to connect to the Jetson.</p>"},{"location":"go2/getting_started/","title":"Getting Started with the Go2","text":"<p>The provides a brief description of the steps needed to get the Go2 up and running with basic control.</p> <p>Take Care</p> <p>These robots are very expensive and it can be relatively easy to damage them. Any and all damage must be report here.</p>"},{"location":"go2/getting_started/#the-box","title":"The Box","text":"<p>For such an expensive robot, the box is surprisingly fragile. When opening the box, ensure that you unclip the two black latches on the front before opening, and try to rest the lid on a table or chair as laying it flat stresses the hinges. When closing, tighten the black strap significantly to avoid stressing the latches on the box.</p>"},{"location":"go2/getting_started/#powering-up","title":"Powering Up","text":"<p>Follow these steps to power on the Go2</p> <ol> <li>Lay the Go2 on the ground, with all 4 foot pads in contact with the floor.</li> <li>Check the robot for any damage. If you find damage, DO NOT USE THE ROBOT and complete the form here.</li> <li>Ensure that the LiDAR spins freely.</li> <li>If you want to use WiFi, plug the USB WiFi adapter (in the box) into the USB port on the Go2 before powering on.</li> <li>Press the battery into the body until both clasps on the front clip into their slots.</li> <li>Press the power button (on the battery) once. The lights on the battery should show green. If they are white, the battery is not seated correctly and should be remove and reinserted.</li> <li>Press and hold the power button again (whilst the lights are still lit up green) until you hear the robot power on.</li> <li>Move away from the robot and wait for it to stand up (this can take up to a minute).</li> </ol>"},{"location":"go2/getting_started/#powering-down","title":"Powering Down","text":"<p>Follow these steps to power off the Go2</p> <ol> <li>Lock the joints by pressing <code>L2+A</code> on the controller.</li> <li>Lay the robot down by pressing <code>L2+A</code> again.</li> <li>Press and hold the power button until the robot turns off.</li> <li>Wait for the LiDAR to stop spinning.</li> <li>Check the robot for any damage. If you find damage complete the form here.</li> <li>Return the robot to the box.</li> </ol>"},{"location":"go2/getting_started/#control","title":"Control","text":"<p>To control the Go2, you can either use the wireless controller or ROS2 Foxy.</p>"},{"location":"go2/getting_started/#wireless-controller","title":"Wireless Controller","text":"<p>To turn on the controller, press the power button on the underside of the controller, then press and hold it for around 10-12 seconds. It should then be connected to the Go2. To turn it off, press the power button then press and hold it for around 3 seconds. The lights should then turn off.</p> <p>In the box, there is an additional controller designed to be clipped to a belt. Do not use this controller unless you have discussed it with an experienced user. You should not need to use this controller.</p>"},{"location":"go2/getting_started/#robot-operating-system","title":"Robot Operating System","text":"<p>The Go2 is configured to use ROS2 Foxy. Do not try to change the ROS version yourself. If this version does not work for you, please contact Toby Godfrey (t.godfrey ~at~ soton.ac.uk) to discuss it further.</p> <p>ROS1 Support</p> <p>ROS1 is not supported and will not be supported. If you must use ROS1, you are advised to migrate your software to ROS2 or use the ROS1-ROS2 bridge.</p> <p>For detailed instructions, view the page on controlling the Go2 with ROS2 Foxy.</p>"},{"location":"go2/resources/","title":"Useful Resources","text":"<p>This document lists useful resources for using the Go2s.</p> <ul> <li>Official Documentation</li> <li>Go2 SDK</li> <li>ROS2 Foxy Documentation</li> </ul>"},{"location":"go2/rgbd_camera/","title":"Using an RGBD Camera","text":"<p>RGBD Cameras</p> <p>RGBD cameras allow for typical colour video and image capture (RGB) alongside the generation of a depth map for each frame (D).</p> <p>TLDR</p> <p>With the SDK running, mount the Intel RealSense D435i to the robot.</p> <p>Then launch the <code>realsense2_camera</code> package</p> <pre><code>ros2 launch realsense2_camera rs_launch.py\n</code></pre> <p>The camera should now be usable. RGB images can be found at <code>/camera/color/image_raw</code> and depth images can be found at <code>/camera/depth/image_rect_raw</code>.</p> <p>We have an Intel RealSense D435i RGBD camera that we have integrated with the Go2. This provides high-definition RGBD cameras over ROS2 topics.</p>"},{"location":"go2/rgbd_camera/#setup","title":"Setup","text":"<p>Firstly, the camera must be mounted to the front of the robot using the provided mount.</p> <p>Info</p> <p>A mount for this can be found in the 3D Models page and can easily be 3D printed.</p> <p>Once the camera has been mounted and plugged into the Jetson via USB, we can start the RealSense package.</p> <pre><code>ros2 launch realsense2_camera rs_launch.py\n</code></pre> <p>The camera should now be working with ROS2. We can verify this by running <code>ros2 topic list</code> and checking for several topics beginning with <code>/camera/</code>.</p>"},{"location":"go2/rgbd_camera/#viewing-the-topic-data","title":"Viewing the Topic Data","text":"<p>You cannot view the images by simply using <code>ros2 topic echo /camera/&lt;TOPIC&gt;</code>. Instead, you can either run <code>rqt</code> and open Visualisation &gt;&gt; Image View. You can then select the topic to visualise.</p> <p>To skip this, we can directly start the image viewer.</p> <pre><code>ros2 run rqt_image_view rqt_image_view\n</code></pre>"},{"location":"go2/ros_control/","title":"ROS2 Control","text":"<p>The ROS2 Foxy package we use to interface with the robot can be found here. This may be ported to a newer version of ROS2 in the future, but there are currently no plans for this.</p> <p>ROS vs. ROS1 vs. ROS2</p> <p>In this document you will see the acronym ROS. Unless specified otherwise ROS will refer to ROS2, specifically ROS2 Foxy. ROS version 1 will be written as ROS1.</p> <p>TLDR</p> <p>Requirements:</p> <ul> <li><code>ROS_DOMAIN_ID = 0</code></li> <li><code>RMW_IMPLEMENTATION = rmw_cyclonedds_cpp</code></li> <li>CycloneDDS version 0.10.2</li> </ul> <p>If you are using WiFi, configure CycloneDDS to use the wireless interface and then connect to the Go2's hotspot with the password <code>hotspot123</code>. You should then see the SDK topics.</p> <p>If you are using Ethernet, configure CycloneDDS to use the wired interface and connect to the Go2. You must have a static IPv4 of <code>192.168.123.222</code>.</p> <p>The Go2 SDK automatically starts when the robot is turned on. You should now be able to interact with the robot using ROS2 by running your ROS code on your computer.</p>"},{"location":"go2/ros_control/#system-layout","title":"System Layout","text":"<p>At present, the system contains three compute units:</p> <ul> <li>The internal MCU</li> <li>The Nvidia Jetson</li> <li>Your PC</li> </ul> <p>Internal MCU</p> <p>The internal MCU is locked by Unitree and is inaccessible. Unitree have been contacted but they did not give me the password &gt;:(.</p>"},{"location":"go2/ros_control/#nvidia-jetson","title":"Nvidia Jetson","text":"<p>The Jetson is where the Go2 SDK runs and can be accessed. For most applications, you should not need to log into the Jetson. The SDK and general setup of the Jetson can be somewhat temperamental. If you make minor changes (e.g. running an additional service), revert them when you are finished. If you need to make major changes, email Toby Godfrey (t.godfrey ~at~ soton.ac.uk) and describe the changes in detail to ensure the Go2 will remain operational.</p> <p>To access the Jetson over Ethernet using SSH, run the command</p> <pre><code>    ssh -X unitree@192.168.123.18\n</code></pre> <p>The password for the Jetson is <code>123</code>. Note that <code>-X</code> is an optional argument to enable X11 forwarding.</p>"},{"location":"go2/ros_control/#using-your-pc","title":"Using Your PC","text":"<p>With the SDK running on the Go2 (which should happen automatically) and your computer connected to the Go2, either via Ethernet or WiFi, you should be able to run your ROS2 code and interact with the topics from the Go2.</p> <p>You must have a matching configuration to that of the Jetson:</p> <ul> <li><code>ROS_DOMAIN_ID = 0</code></li> <li><code>RMW_IMPLEMENTATION = rmw_cyclonedds_cpp</code></li> <li>CycloneDDS version <code>0.10.2</code></li> </ul> <p>To install ROS2 Foxy, follow the tutorial here. If you don't want to install it, or you have an incompatible setup, we have a Docker container which should work out of the box. Download the Dockerfile and follow the instructions on Running with Docker.</p> <p>The Jetson and internal MCU use CycloneDDS 0.10.2 as the ROS2 middleware vendor. Communication may not work if you use a different version of CycloneDDS. If you are not using the Docker container, we must install the correct version of CycloneDDS. To do so, follow the instructions on Running without Docker.</p>"},{"location":"go2/ros_control/#connecting-over-ethernet","title":"Connecting Over Ethernet","text":"<p>To use ROS over Ethernet, simply connect your PC and the Jetson with an Ethernet cable and set the wired IPv4 address of your PC to <code>192.168.123.222</code>. The Go2 does not support DHCP and we have observed strange behaviour when we do not have this static IPv4 address set. If you can successfully ping <code>192.168.123.18</code>, you are connected to the robot and can start interacting with it.</p>"},{"location":"go2/ros_control/#connecting-over-wifi","title":"Connecting Over WiFi","text":"<p>To use ROS over WiFi, the USB WiFi adapter has to be connected before the Go2 is powered up. A minute or two after the robot has stood up, you should see a WiFi network called <code>go2</code>. Connect to this network with the password <code>hotspot123</code>. You should now be connected to the robot. To test, check if you can successfully ping the network gateway. You can now interface with the robot.</p>"},{"location":"go2/ros_control/#ros-usage","title":"ROS Usage","text":""},{"location":"go2/ros_control/#general-control","title":"General Control","text":"<p>If using the Go2 over Ethernet, you will have access to all topics from both the Jetson and the internal MCU. If using WiFi, you will only have access to the SDK topics (from the Jetson). The topics from the SDK should be sufficient.</p> <p>To move the robot, publish a <code>Twist</code> message to the <code>/cmd_vel</code> topic. This allows you to specify a desired linear and angular velocity for the robot.</p> <p>A Word of Warning</p> <p>The robot will move as soon as you publish to <code>/cmd_vel</code>. Ensure there is adequate space around the robot and all people are out the way. When using <code>/cmd_vel</code> there is no inbuilt collision avoidance so use caution. You are responsible so ensure neither the robot nor the lab are damaged during your experiments.</p> <p>Robot pose data can be retrieve by subscribing to the <code>/odom</code> topic. This returns <code>Odometry</code> messages. These messages can provide a 3 dimensional position vector (relative to the position of the robot when ROS was started) and a quaternion for the orientation of the robot.</p> <p>To retrieve data from the robot's LiDAR, subscribe to the <code>/scan</code> topic. This returns a <code>LaserScan</code> message. This topic requires a different QoS policy than most, if you cannot receive messages from it, try using a <code>ReliabilityPolicy</code> of <code>RMW_QOS_POLICY_RELIABILITY_RELIABLE</code>.</p> <p>For low level joint information, subscribe to the <code>/joint_states</code> topic.</p> <p>There are other topics which are more niche in their uses.</p> <p>Success</p> <p>We have successfully integrated an Intel RealSense D435i RGBD camera. See here for more information.</p> <p>Bug</p> <p>We also have a Livox MID-360 LiDAR which is yet to be integrated with the robot. See here for more information.</p>"},{"location":"go2/ros_control/#pre-defined-actions","title":"Pre-Defined Actions","text":"<p>The Go2 has many pre-defined actions (listed on the controller), e.g. sitting or jumping. These are accessible using ROS, simply run</p> <pre><code>    ros2 service call /mode go2_interfaces/srv/Mode \"mode: '&lt;MODE&gt;'\"\n</code></pre> <p>The options for <code>&lt;MODE&gt;</code> are:</p> <ul> <li><code>damp</code> \u2014 lock all motor joints (this is high priority and can be used for emergency stops)</li> <li><code>balance_stand</code> \u2014 unlock all joints and move into balance stand mode, the attitude and height of the torso will always remain balanced independent of terrain</li> <li><code>stop_move</code> \u2014 stop any current motion</li> <li><code>stand_up</code> \u2014 stand up if it is laying down</li> <li><code>stand_down</code> \u2014 lay down on its chest (this is useful to put it in a safe state before turning it off)</li> <li><code>sit</code> \u2014 sit down</li> <li><code>rise_sit</code> \u2014 rise from being sat down</li> <li><code>hello</code> \u2014 wave</li> <li><code>stretch</code> \u2014 typical dog-like stretch</li> <li><code>wallow</code> \u2014 DO NOT RUN THIS MODE, the robot will throw itself sideways onto it's back</li> <li><code>scrape</code> \u2014</li> <li><code>front_flip</code> \u2014 DO NOT RUN THIS MODE, the robot will do a front flip and may get damaged</li> <li><code>front_jump</code> \u2014 jump forward</li> <li><code>front_pounce</code> \u2014</li> <li><code>dance1</code> \u2014 fun dance</li> <li><code>dance2</code> \u2014 fun dance</li> <li><code>finger_heart</code> \u2014 sit on its back legs and draw a heart</li> </ul> <p>Using these Modes</p> <p>These modes are more of a gimmick and unlikely to be useful for your research. It is strongly recommended, if you do want to see these actions, to use the wireless controller to do so. Instructions on how to do that are printed on the controller. If you use ROS, it is very easy to run a new action which could damage the robot.</p>"},{"location":"go2/ros_control/#go2-ros2-sdk","title":"Go2 ROS2 SDK","text":"<p>Accessing the SDK</p> <p>The typical user should not have to interact with the SDK. This section is mainly included for completeness.</p> <p>Unitree support for ROS2 is poor and so we do not use the default SDK. The SDK we use is here which is a fork of this.</p>"},{"location":"go2/ros_control/#systemd-service","title":"<code>systemd</code> Service","text":"<p>The SDK runs as a <code>systemd</code> service on the Jetson and should start automatically at boot. To check this run</p> <pre><code>    systemctl status go2-sdk.service\n</code></pre> <p>If you want to run the SDK manually (e.g. for debugging), make sure to stop the service.</p> <pre><code>    sudo systemctl stop go2-sdk.service\n</code></pre>"},{"location":"go2/ros_control/#building-from-source","title":"Building from Source","text":"<p>In order to build from source, ensure that the <code>ros2_ws</code> directory has not been sourced. You will likely need to comment out the line <code>source ~/ros2_ws/install/setup.bash</code> in the file <code>~/.ros2_env</code>. Restart the shell then proceed to the next steps.</p> <p>As the package already exists, we must remove it. It is good practice to clean the workspace too.</p> <pre><code>    cd ~/ros2_ws\n    rm -r log/ install/ build/      # Clean the workspace\n    rm -r src/go2_robot             # Remove the SDK package\n</code></pre> <p>The <code>src</code> directory will also have a package called <code>HesaiLidar_ROS_2.0</code>. This package is required by the SDK even though we do not have this LiDAR. There are plans to remove this requirement in the future but for now leave the package untouched.</p> <p>We can then gather our sources for the SDK.</p> <pre><code>    cd ~/ros2_ws/src\n    git clone https://github.com/tgodfrey0/go2_robot.git        # Clone the SDK\n    RUN git clone https://github.com/nlohmann/json.git          # Clone a required library\n    mv json/include/nlohmann go2_robot/go2_driver/include/      # Move the library to the ROS package\n    rm -rf json                                                 # Remove the library repository\n</code></pre> <p>Now we can build it.</p> <pre><code>    cd ~/ros2_ws\n    rosdep update \n    rosdep install --from-paths src --ignore-src -r -y --rosdistro $ROS_DISTRO --include-eol-distros \n    colcon build --symlink-install \n    source install/setup.bash \n</code></pre> <p>If all packages build successfully we can now use the Go2 with ROS2.</p> <p>To start the SDK, run</p> <pre><code>    ros2 launch go2_bringup go2.launch.py\n</code></pre> <p>Once this is working, remember to uncomment the line to source the ROS workspace in <code>~/.ros2_env</code>.</p>"},{"location":"go2/troubleshooting/","title":"Troubleshooting","text":"<p>A list of common issues and their solutions are presented below.</p>"},{"location":"go2/troubleshooting/#cant-see-topics-over-wifi","title":"Can't see topics over WiFi","text":"<p>If you cannot see any topics over WiFi, firstly, ensure you have connected to the WiFi network generated by the robot (probably called <code>go2</code> with the password <code>hotspot123</code>). The following criteria must also be met.</p> <ul> <li><code>ROS_DOMAIN_ID = 0</code></li> <li><code>RMW_IMPLEMENTATION = rmw_cyclonedds_cpp</code></li> <li>CycloneDDS version 0.10.2</li> </ul> <p>If you still cannot see the topics, check that CycloneDDS is using the correct interface. Run <code>echo $CYCLONEDDS_URI</code> to see whether it points to a file or contains the configuration itself. Then check that the <code>NetworkInterface</code> tag has the name of the interface which is connected to the <code>go2</code> network. You may need to run <code>ros2 daemon stop</code> then <code>ros2 daemon start</code> for the changes to take effect.</p>"},{"location":"go2/troubleshooting/#cant-see-topics-over-ethernet","title":"Can't see topics over Ethernet","text":"<p>If you cannot see any topics over Ethernet, check that you are connected to the robot. Try to ping <code>192.168.123.18</code> and check the destination is reachable.</p> <p>If this connection works, ensure that the wired connection on your laptop has a static IPv4 address by disabling DHCP, setting the IPv4 address to <code>192.168.123.222</code> and the subnet to <code>255.255.255.0</code>.</p> <p>The ROS installation must also meet the requirements below.</p> <ul> <li><code>ROS_DOMAIN_ID = 0</code></li> <li><code>RMW_IMPLEMENTATION = rmw_cyclonedds_cpp</code></li> <li>CycloneDDS version 0.10.2</li> </ul> <p>If you still cannot see the topics, check that CycloneDDS is using the correct interface. Run <code>echo $CYCLONEDDS_URI</code> to see whether it points to a file or contains the configuration itself. Then check that the <code>NetworkInterface</code> tag has the name of the interface which is connected to the robot. You may need to run <code>ros2 daemon stop</code> then <code>ros2 daemon start</code> for the changes to take effect.</p>"},{"location":"go2/troubleshooting/#cant-view-ros-messages-over-wifi","title":"Can't view ROS messages over WiFi","text":"<p>There is a current known issue that prevents consistent viewing of messages sent via ROS over WiFi. If you run <code>ros2 topic echo /&lt;TOPIC&gt;</code> and the output hangs, it is likely the WiFi adapter bandwidth is saturated and packets are being dropped. This is a problem we are currently working on. If you must view the topics, use Ethernet.</p>"},{"location":"turtlebot3/","title":"TurtleBot3","text":"<p>This directory contains the documentation for the TurtleBot3 platform.</p> <p>We currently have two TurtleBot3 platforms in the lab.</p> <p>If you have not used the TurtleBot3s before, please see Getting Started.</p> <p>For all other information about the TurtleBot3s, please navigate to the relevant page.</p> <ul> <li>Getting Started</li> <li>New Robot Setup</li> <li>ROS2 Control</li> <li>Troubleshooting</li> <li>Useful Resources</li> </ul>"},{"location":"turtlebot3/getting_started/","title":"Getting Started with the TurtleBot3s","text":"<p>The TurtleBot3 robots are constructed with three parallel plates, the bottom plate has the battery, the middle plate houses a Raspberry Pi 4 and an OpenCR control board, and the top plate contains the LiDAR and a Raspberry Pi Camera v2.</p> <p>Take Care</p> <p>Whilst these robots may look cheap, they are not. They are relatively robust, but not indestructible. Any and all damage must be report here.</p>"},{"location":"turtlebot3/getting_started/#powering-up","title":"Powering Up","text":"<p>Follow these steps to power on the TurtleBot3</p> <ol> <li>Check the robot for any damage. If you find damage, DO NOT USE THE ROBOT and complete the form here.</li> <li>Ensure that the LiDAR spins freely.</li> <li>Connect the battery to the OpenCR board. The end of the cable from the OpenCR board should be on the bottom plate next to the battery.</li> <li>Turn on the OpenCR board by using the switch on the blue OpenCR board directly above the battery.</li> <li>Wait for the Raspberry Pi to power on.</li> </ol>"},{"location":"turtlebot3/getting_started/#powering-down","title":"Powering Down","text":"<p>Follow these steps to power off the TurtleBot3</p> <ol> <li>If you have access to a shell on the Raspberry Pi, power it off using the <code>poweroff</code> command.</li> <li>Turn off the OpenCR control board using the switch above the battery area.</li> <li>Unplug the battery from the OpenCR board.</li> <li>Check the robot for any damage. If you find damage and complete the form here.</li> <li>Return the robot to the box.</li> </ol>"},{"location":"turtlebot3/getting_started/#accessing-the-raspberry-pi","title":"Accessing the Raspberry Pi","text":"<p>The main compute unit on each TurtleBot3 is the Raspberry Pi 4 positioned towards the back of the robot on the second tier. This can be accessed by connecting a keyboard and a HDMI cable. The username is <code>ubuntu</code> and the password is <code>raspberry</code>.</p>"},{"location":"turtlebot3/getting_started/#connecting-to-wifi","title":"Connecting to WiFi","text":"<p>The Raspberry Pi has an onboard wireless chip. The easiest way to connect to a WiFi network is with <code>nmtui</code>.</p> <p>Simply run</p> <pre><code>    sudo nmtui\n</code></pre> <p>And click on <code>Activate a connection</code>.</p>"},{"location":"turtlebot3/getting_started/#control","title":"Control","text":"<p>There are wireless controller for the TurtleBot3s, however they have not be set up or tested. You must use ROS to control the robots.</p>"},{"location":"turtlebot3/getting_started/#keyboard-control","title":"Keyboard Control","text":"<p>To control the robot with your keyboard (simple WASD), on your computer launch the keyboard control package. (Your PC must be connected to the robots over the network for ROS to communicate with it.)</p> <pre><code>    ros2 run turtlebot3_teleop teleop_keyboard\n</code></pre> <p>This will allow you to control the linear and angular velocity of the robot.</p>"},{"location":"turtlebot3/getting_started/#programmatic-control","title":"Programmatic Control","text":"<p>The TurtleBot3 is configured to use ROS2 Humble. Do not try to change the ROS version yourself. If this version does not work for you, please contact Toby Godfrey (t.godfrey ~at~ soton.ac.uk) to discuss it further.</p> <p>ROS1 Support</p> <p>ROS1 is not supported and will not be supported. If you must use ROS1, you are advised to migrate your software to ROS2 or use the ROS1-ROS2 bridge.</p> <p>For detailed instructions, view the page on controlling the TurtleBot3 with ROS2 Humble.</p>"},{"location":"turtlebot3/resources/","title":"Useful Resources","text":"<p>This document lists useful resources for using the TurtleBot3s.</p> <ul> <li>Official Documentation</li> <li>ROS2 Humble Documentation</li> <li>Custom Linux Image</li> <li>MRS Launcher</li> </ul>"},{"location":"turtlebot3/ros_control/","title":"ROS2 Control","text":"<p>One can either log into the Raspberry Pi using SSH or by connecting a keyboard and display. The username is <code>ubuntu</code> and the password is <code>turtlebot</code>.</p>"},{"location":"turtlebot3/ros_control/#bringup","title":"Bringup","text":"<p>This should be run on the Raspberry Pi inside the robot. See above on how to access the robot.</p> <p>The SDK must be started to enable ROS control of the robot. We can launch this as follows</p> <pre><code>    ros2 launch turtlebot3_bringup robot.launch.py\n</code></pre> <p>This should start the SDK can allow you to interact with the robot. The rest of your code can (normally) be run from your own PC now.</p>"},{"location":"turtlebot3/ros_control/#topics","title":"Topics","text":"<p>The TurtleBot3 produces standard topics for basic robot control.</p> <p>To move the robot, publish a <code>Twist</code> message to the <code>/cmd_vel</code> topic. This allows you to specify a desired linear and angular velocity for the robot.</p> <p>A Word of Warning</p> <p>The robot will move as soon as you publish to <code>/cmd_vel</code>. Ensure there is adequate space around the robot and all people are out the way. When using <code>/cmd_vel</code> there is no inbuilt collision avoidance so use caution. You are responsible so ensure neither the robot nor the lab are damaged during your experiments.</p> <p>Robot pose data can be retrieve by subscribing to the <code>/odom</code> topic. This returns <code>Odometry</code> messages. These messages can provide a 3 dimensional position vector (relative to the position of the robot when ROS was started) and a quaternion for the orientation of the robot.</p> <p>To retrieve data from the robot's LiDAR, subscribe to the <code>/scan</code> topic. This returns a <code>LaserScan</code> message. This topic requires a different QoS policy than most, if you cannot receive messages from it, try using a <code>ReliabilityPolicy</code> of <code>RMW_QOS_POLICY_RELIABILITY_RELIABLE</code>.</p> <p>There are other topics which are more niche in their uses.</p>"},{"location":"turtlebot3/setup/","title":"TurtleBot3 Setup","text":"<p>If you are setting up a new TurtleBot3, you can follow the guide on the Robotis website.</p> <p>This can be tedious so we have created a custom Linux image to do this all for you.</p>"},{"location":"turtlebot3/setup/#using-the-custom-linux-image","title":"Using the Custom Linux Image","text":"<p>In order to speed up the deployment of TurtleBots, we created a custom Linux image using Packer to provide you with a Linux image that has almost all of the settings pre-configured, and all of the TurtleBot3 features set up.</p> <p>First, clone the GitHub repository found at <code>tgodfrey0/turtlebot3_custom_image</code>. The script uses <code>podman</code> (a better version of Docker) to build the image so this must be installed first.</p> <p>Then you can <code>cd</code> into the directory and run the build script. You must specify the type of TurtleBot3 (either burger or waffle); you may also specify whether the image should not be compressed once it has been made, and whether a WiFi network should be added.</p> <pre><code>./build.sh waffle/burger [addconnection] [nocompress]\n</code></pre> <p>Note: optional arguments are in brackets.</p> <p>This will then build a configure an Ubuntu server image with ROS2 Humble and all other packages and configurations to setup a TurtleBot3. the <code>.img</code> file can then be flashed to the Raspberry Pi on the robot.</p>"},{"location":"turtlebot3/troubleshooting/","title":"Troubleshooting","text":""},{"location":"turtlebot3/troubleshooting/#cant-see-the-topics","title":"Can't see the topics","text":"<p>If you cannot see the topics from the robots, ensure they are connected to the same network and that the SDK is running.</p>"},{"location":"uav/","title":"UAVs","text":"<p>This directory contains the documentation for our custom UAV platform.</p> <p>Eventually we should have at least 15 UAVs.</p> <p>If you have not used these drones before, please email Toby Godfrey (t.godfrey ~at~ soton.ac.uk) BEFORE you start working with them and see the Getting Started page.</p> <p>For all other information about the Go2s, please navigate to the relevant page.</p> <ul> <li>Getting Started</li> </ul> <p>These UAVs were designed and developed by Toby Godfrey. For a detailed discussion, feel free to email him at t.godfrey ~at~ soton.ac.uk.</p>"},{"location":"uav/build_instructions/","title":"Building the UAVs","text":""},{"location":"uav/build_instructions/#component-list","title":"Component List","text":""},{"location":"uav/build_instructions/#design-files","title":"Design Files","text":""},{"location":"uav/build_instructions/#bom","title":"BOM","text":"<p>The BOM can be downloaded from here.</p>"},{"location":"uav/build_instructions/#carbon-fibre-machining-companies","title":"Carbon Fibre Machining Companies","text":"<p>The base frame of the UAV is machined from a Carbon Fibre sheet. Unless you want to do this yourself, we recommend using one of the following companies for manufacturing the frames:</p> <ul> <li>CNC Madness (Canada) \u2014 Good price and quality, great if you are not in a rush</li> <li>Carbon Fibre Tubes (UK) \u2014 More expensive than CNC Madness, but they are located in Fareham and registered as a supplier with the university so better for quick turnarounds</li> </ul> <p>Altering the frame design</p> <p>If you need to change the design of the frame, maybe to accommodate different components, you are strongly encouraged to 3D print a prototype before ordering the frame. This will help you identify any potential issues with the design before investing significant time and money into having the frames manufactured. Please contact Toby Godfrey (t.godfrey ~at~ soton.ac.uk) with your updated designs so we can add them to these resources.</p>"},{"location":"uav/build_instructions/#wiring","title":"Wiring","text":""},{"location":"uav/build_instructions/#assembly","title":"Assembly","text":"<p>Nylon Locking Nuts</p> <p>Nylon Locking Nuts (A.K.A. Nylocks) are effectively single use. Once they have been tightened through the nylon ring they should not be removed otherwise the locking ring will be damaged and performance will degrade. Before tightening the bolt, ensure you will not need to remove that component again. It may be a good idea to leave all of the locking nuts off until the end of assembly.</p> <ol> <li>Pass the M3x16(?) countersunk bolts from the bottom of the frame through the 4 larger countersunk holes and use an M3 nut to lock the bolt in place. Ensure the bolt is seated in the countersink bore on the underside of the frame. Place the flight controller (with the rubber grommets) onto the bolts and then use 4 M3 Nylock nuts to tightly lock the flight controller in place. Make sure the arrow on the board is on the top and facing forwards.</li> <li>Attach the cable between the flight controller and the ESC, then pass the M2x14(?) coutnersunk bolts through the smaller 4 holes in the middle of the frame. Then use an M2 nut to lock those bolts to the frame. Place the ESC (with the rubber grommets) onto the bolts and then use 4 M2 Nylocks to secure the ESC in place.</li> <li>Pass 4 M2x8 bolts through the 4 motor mount holes on one arm. Place the motor on top and thread the bolts into the motors. Repeat for the other 3 motors.</li> <li>Place the radio module and the GNSS module into their respective mounts, and place them either side of the rear mounting arm. Pass one M3x14 bolt through each hole, and use an M3 Nylock to secure each bolt and keep the mounts flush against the frame.</li> <li>Place the optical flow board on the underside of the mount between the front motors. Use M3x12 bolts and M3 Nylocks to secure the sensor to the frame. Ensure the arrow on the board is facing forwards.</li> <li>Align the battery cage below the frame and use 4 M3 bolts through the mounting holes. The bolt length will depend on whether standoffs or Nylock nuts are used. Attach the relevant 'nut' on the other side of the bolt and ensure the battery cage does not move.</li> </ol>"},{"location":"uav/build_instructions/#expansion-plates","title":"Expansion Plates","text":""},{"location":"uav/build_instructions/#calibration","title":"Calibration","text":""},{"location":"uav/getting_started/","title":"Getting Started with the UAVs","text":""}]}